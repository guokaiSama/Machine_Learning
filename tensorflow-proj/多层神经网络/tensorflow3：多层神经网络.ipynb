{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST手写体识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow 已经把 mnist 数据集集成在 examples 里面了\n",
    "# 在这里 import 数据输入的部分\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入`mnist`数据集 ,注意：需要下载mnist数据集，存放在当前程序的MNIST_data文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`one_hot`**将一个数`n`映射到一个向量, 这个向量的第`n`个元素是`1`, 其他元素都是`0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist.train\n",
    "test_set = mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(ncols=6, nrows=2)\n",
    "plt.tight_layout(w_pad=-2.0, h_pad=-8.0)\n",
    "\n",
    "# 调用next_batch方法来一次性获取12个样本,\n",
    "# 这里有一个`shuffle`参数, 表达是否打乱样本间的顺序\n",
    "images, labels = train_set.next_batch(12, shuffle=False)\n",
    "\n",
    "for ind, (image, label) in enumerate(zip(images, labels)):\n",
    "    # image 是一个 784 维的向量, 是图片进行拉伸产生的, 这里我们给它 reshape 回去\n",
    "    image = image.reshape((28, 28))\n",
    "    \n",
    "    # label 是一个 10 维的向量, 哪个下标处的值为1 说明是数字几\n",
    "    label = label.argmax()\n",
    "\n",
    "    row = ind // 6\n",
    "    col = ind % 6\n",
    "    axes[row][col].imshow(image, cmap='gray') # 灰度图\n",
    "    axes[row][col].axis('off')\n",
    "    axes[row][col].set_title('%d' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义深度网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(layer_input, output_depth, scope='hidden_layer', reuse=None):\n",
    "    input_depth = layer_input.get_shape()[-1]\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        # 注意这里的初始化方法是truncated_normal\n",
    "        w = tf.get_variable(initializer=tf.truncated_normal_initializer(stddev=0.1), shape=(input_depth, output_depth), name='weights')\n",
    "        # 注意这里用 0.1 对偏置进行初始化\n",
    "        b = tf.get_variable(initializer=tf.constant_initializer(0.1), shape=(output_depth), name='bias')\n",
    "        net = tf.matmul(layer_input, w) + b\n",
    "        \n",
    "        return net\n",
    "\n",
    "def DNN(x, output_depths, scope='DNN', reuse=None):\n",
    "    net = x\n",
    "    for i, output_depth in enumerate(output_depths):\n",
    "        net = hidden_layer(net, output_depth, scope='layer%d' % i, reuse=reuse)\n",
    "        # 注意这里的激活函数\n",
    "        net = tf.nn.relu(net)\n",
    "    # 数字分为0, 1, ..., 9 所以这是10分类问题\n",
    "    # 对应于 one_hot 的标签, 所以这里输出一个 10维 的向量\n",
    "    net = hidden_layer(net, 10, scope='classification', reuse=reuse)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义占位符\n",
    "input_ph = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "label_ph = tf.placeholder(shape=(None, 10), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个4层的神经网络, 它的隐藏节点数分别为: 400, 200, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN(input_ph, [400, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个分类问题, 因此我们采用交叉熵来计算损失函数\n",
    "loss = tf.losses.softmax_cross_entropy(logits=dnn, onehot_labels=label_ph)\n",
    "\n",
    "# 下面定义的是正确率\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(dnn, axis=-1), tf.argmax(label_ph, axis=-1)), dtype=tf.float32))\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1000: train_loss: 0.508492 train_acc: 0.859375 test_loss: 0.381910 test_acc: 0.890625\n",
      "STEP 2000: train_loss: 0.273127 train_acc: 0.906250 test_loss: 0.308092 test_acc: 0.937500\n",
      "STEP 3000: train_loss: 0.300943 train_acc: 0.921875 test_loss: 0.129283 test_acc: 0.968750\n",
      "STEP 4000: train_loss: 0.287253 train_acc: 0.906250 test_loss: 0.137666 test_acc: 0.953125\n",
      "STEP 5000: train_loss: 0.158111 train_acc: 0.968750 test_loss: 0.343043 test_acc: 0.921875\n",
      "STEP 6000: train_loss: 0.049266 train_acc: 0.984375 test_loss: 0.234881 test_acc: 0.937500\n",
      "STEP 7000: train_loss: 0.148513 train_acc: 0.953125 test_loss: 0.145246 test_acc: 0.937500\n",
      "STEP 8000: train_loss: 0.168960 train_acc: 0.953125 test_loss: 0.194879 test_acc: 0.921875\n",
      "STEP 9000: train_loss: 0.077116 train_acc: 0.968750 test_loss: 0.124628 test_acc: 0.968750\n",
      "STEP 10000: train_loss: 0.121345 train_acc: 0.984375 test_loss: 0.105184 test_acc: 0.937500\n",
      "STEP 11000: train_loss: 0.078549 train_acc: 0.984375 test_loss: 0.070529 test_acc: 0.968750\n",
      "STEP 12000: train_loss: 0.135863 train_acc: 0.968750 test_loss: 0.040104 test_acc: 1.000000\n",
      "STEP 13000: train_loss: 0.083056 train_acc: 0.953125 test_loss: 0.166866 test_acc: 0.953125\n",
      "STEP 14000: train_loss: 0.046393 train_acc: 0.984375 test_loss: 0.253278 test_acc: 0.921875\n",
      "STEP 15000: train_loss: 0.054998 train_acc: 0.984375 test_loss: 0.076912 test_acc: 0.968750\n",
      "STEP 16000: train_loss: 0.059943 train_acc: 0.984375 test_loss: 0.063205 test_acc: 0.968750\n",
      "STEP 17000: train_loss: 0.015443 train_acc: 1.000000 test_loss: 0.161310 test_acc: 0.937500\n",
      "STEP 18000: train_loss: 0.004172 train_acc: 1.000000 test_loss: 0.124560 test_acc: 0.968750\n",
      "STEP 19000: train_loss: 0.044374 train_acc: 0.984375 test_loss: 0.123954 test_acc: 0.968750\n",
      "STEP 20000: train_loss: 0.033314 train_acc: 1.000000 test_loss: 0.158871 test_acc: 0.953125\n",
      "Train Done!\n",
      "------------------------------\n",
      "Train loss: 0.049397\n",
      "Train accuracy: 0.986909\n",
      "Test loss: 0.090308\n",
      "Test accuracy: 0.971000\n"
     ]
    }
   ],
   "source": [
    "# 我们训练20000次\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(20000):\n",
    "    # 获取 batch_size个训练样本\n",
    "    images, labels = train_set.next_batch(batch_size)\n",
    "    sess.run(train_op, feed_dict={input_ph: images, label_ph: labels})\n",
    "    if e % 1000 == 999:\n",
    "        # 获取 batch_size 个测试样本\n",
    "        test_imgs, test_labels = test_set.next_batch(batch_size)\n",
    "        # 计算在当前样本上的训练以及测试样本的损失值和正确率\n",
    "        loss_train, acc_train = sess.run([loss, acc], feed_dict={input_ph: images, label_ph: labels})\n",
    "        loss_test, acc_test = sess.run([loss, acc], feed_dict={input_ph: test_imgs, label_ph: test_labels})\n",
    "        print('STEP {}: train_loss: {:.6f} train_acc: {:.6f} test_loss: {:.6f} test_acc: {:.6f}'.format(e + 1, loss_train, acc_train, loss_test, acc_test))\n",
    "\n",
    "print('Train Done!')\n",
    "print('-'*30)\n",
    "\n",
    "# 计算所有训练样本的损失值以及正确率\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "for _ in range(train_set.num_examples // 100):\n",
    "    image, label = train_set.next_batch(100)\n",
    "    loss_train, acc_train = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    train_loss.append(loss_train)\n",
    "    train_acc.append(acc_train)\n",
    "\n",
    "print('Train loss: {:.6f}'.format(np.array(train_loss).mean()))\n",
    "print('Train accuracy: {:.6f}'.format(np.array(train_acc).mean()))\n",
    "\n",
    "# 计算所有测试样本的损失值以及正确率\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for _ in range(test_set.num_examples // 100):\n",
    "    image, label = test_set.next_batch(100)\n",
    "    loss_test, acc_test = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    test_loss.append(loss_test)\n",
    "    test_acc.append(acc_test)\n",
    "\n",
    "print('Test loss: {:.6f}'.format(np.array(test_loss).mean()))\n",
    "print('Test accuracy: {:.6f}'.format(np.array(test_acc).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练集上大约0.98的正确率, 在测试集上大约0.97的正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard & `tf.summary`\n",
    "\n",
    "`Tensorboard`和`tf.summary`结合起来可以实现可视化训练. \n",
    "\n",
    "首先介绍一下`tf.summary`, 它能够收集训练过程中的各种`tensor`的信息并把它保存起来以供`Tensorboard`读取并展示. 按照下面的方法来使用它:\n",
    "\n",
    "### 构造`summary`\n",
    "- - -\n",
    "- 如果你想收集一个标量或者一个数的`tensor`的信息, 比如上面的`loss`\n",
    "```python\n",
    "loss_sum = tf.summary.scalar('loss', loss)\n",
    "```\n",
    "\n",
    "- - -\n",
    "- 如果你想收集一个`tensor`的分布情况, 这个`tensor`可以是任意形状, 比如我们定义了一个`(784, 400)`的权重`w`\n",
    "```python\n",
    "w_hist = tf.summary.histogram('w_hist', w)\n",
    "```\n",
    "- - -\n",
    "- 如果你想收集一个4维的1-通道(灰度图), 3-通道(RGB), 4-通道(RGBA)的`tensor`的变化, 比如我们输出了一个`(1, 8, 8, 1)`的灰度图`image`\n",
    "```python\n",
    "image_sum = tf.summary.image('image', image)\n",
    "```\n",
    "- - -\n",
    "- 如果你想收集一个3维(batch, frame, channel), 2维(batch, frame)的变化, 比如我们输出了一个`(10, 50, 3)`的`tensor`:`audio`\n",
    "```python\n",
    "audio_sum = tf.summary.audio('audio', audio)\n",
    "```\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置计算图\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 重新定义占位符\n",
    "input_ph = tf.placeholder(shape=(None, 784), dtype=tf.float32)\n",
    "label_ph = tf.placeholder(shape=(None, 10), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造权重, 用`truncated_normal`初始化\n",
    "def weight_variable(shape):\n",
    "    init = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "# 构造偏置, 用`0.1`初始化\n",
    "def bias_variable(shape):\n",
    "    init = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造添加`variable`的`summary`的函数\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        # 计算平均值\n",
    "        mean = tf.reduce_mean(var)\n",
    "        # 将平均值添加到`summary`中, 这是一个数值, 所以我们用`tf.summary.scalar`\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        \n",
    "        # 计算标准差\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        # 将标准差添加到`summary`中\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        \n",
    "        # 添加最大值,最小值`summary`\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        \n",
    "        # 添加这个变量分布情况的`summary`, 我们希望观察它的分布, 所以用`tf.summary.histogram`\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造一个隐藏层\n",
    "def hidden_layer(x, output_dim, scope='hidden_layer', act = tf.nn.relu, reuse=None):\n",
    "    # 获取输入的`depth`\n",
    "    input_dim = x.get_shape().as_list()[-1]\n",
    "    \n",
    "    with tf.name_scope(scope):\n",
    "        with tf.name_scope('weight'):\n",
    "            # 构造`weight`\n",
    "            weight = weight_variable([input_dim, output_dim])\n",
    "            # 添加`weight`的`summary`\n",
    "            variable_summaries(weight)\n",
    "            \n",
    "        with tf.name_scope('bias'):\n",
    "            # 构造`bias`\n",
    "            bias = bias_variable([output_dim])\n",
    "            # 添加`bias`的`summary`\n",
    "            variable_summaries(bias)\n",
    "            \n",
    "        with tf.name_scope('linear'):\n",
    "            # 计算`xw+b`\n",
    "            preact = tf.matmul(x, weight) + bias\n",
    "            # 添加激活层之前输出的分布情况到`summary`\n",
    "            tf.summary.histogram('pre_activation', preact)\n",
    "            \n",
    "        # 经过激活层`act`\n",
    "        output = act(preact)\n",
    "        # 添加激活后输出的分布情况到`summary`\n",
    "        tf.summary.histogram('output', output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造深度神经网络\n",
    "def DNN(x, output_depths, scope='DNN_with_sums', reuse=None):\n",
    "    with tf.name_scope(scope):\n",
    "        net = x\n",
    "        for i, output_depth in enumerate(output_depths):\n",
    "            net = hidden_layer(net, output_depth, scope='hidden%d' % (i + 1), reuse=reuse)\n",
    "        # 最后有一个分类层\n",
    "        net = hidden_layer(net, 10, scope='classification', act=tf.identity, reuse=reuse)\n",
    "        return net\n",
    "\n",
    "dnn_with_sums = DNN(input_ph, [400, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义`loss`, `acc`, `train_op`\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    loss = tf.losses.softmax_cross_entropy(logits=dnn_with_sums, onehot_labels=label_ph)\n",
    "    tf.summary.scalar('cross_entropy', loss)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(dnn_with_sums, axis=-1), tf.argmax(label_ph, axis=-1)), dtype=tf.float32))\n",
    "    tf.summary.scalar('accuracy', acc)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    lr = 0.01\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 融合`summary`\n",
    "- - -\n",
    "- 我们可以把前面定义的所有`summary`都融合成一个`summary`\n",
    "```python\n",
    "merged = tf.summary.merge_all()\n",
    "```\n",
    "- - -\n",
    "- 也可以只是融合某些`summary`\n",
    "```python\n",
    "merged = tf.summary.merge([loss_sum, image_sum])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出`summary`\n",
    "---\n",
    "`summary`是需要导出到外部文件的\n",
    "- 首先定义一个文件读写器\n",
    "```python\n",
    "summary_writer = tf.summary.FileWriter('summaries', sess.graph)\n",
    "```\n",
    "- - -\n",
    "- 然后在训练的过程中, 在你希望的时候运行一次`merged`或者是你之前自己定义的某个通过`summary`定义的`op`\n",
    "```python\n",
    "summaries = sess.run(merged, feed_dict={...})\n",
    "```\n",
    "- - -\n",
    "- 然后将这个`summaries`写入到`summari_writer`内\n",
    "```python\n",
    "summary_writer.add_summary(summaries, step)\n",
    "```\n",
    "注意`step`表示你当前训练的步数, 当然你也可以设定为其他你想要用的数值\n",
    "\n",
    "- - -\n",
    "- 最后关闭文件读写器\n",
    "```python\n",
    "summary_writer.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('test_summary/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('test_summary/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1000: train_loss: 0.425742 train_acc: 0.906250 test_loss: 0.335134 test_acc: 0.906250\n",
      "STEP 2000: train_loss: 0.437294 train_acc: 0.859375 test_loss: 0.348037 test_acc: 0.843750\n",
      "STEP 3000: train_loss: 0.161168 train_acc: 0.937500 test_loss: 0.271150 test_acc: 0.921875\n",
      "STEP 4000: train_loss: 0.070931 train_acc: 0.984375 test_loss: 0.083520 test_acc: 0.984375\n",
      "STEP 5000: train_loss: 0.078938 train_acc: 1.000000 test_loss: 0.082872 test_acc: 0.968750\n",
      "STEP 6000: train_loss: 0.183314 train_acc: 0.953125 test_loss: 0.063439 test_acc: 0.984375\n",
      "STEP 7000: train_loss: 0.038420 train_acc: 1.000000 test_loss: 0.097311 test_acc: 0.953125\n",
      "STEP 8000: train_loss: 0.086733 train_acc: 0.953125 test_loss: 0.127061 test_acc: 0.953125\n",
      "STEP 9000: train_loss: 0.225148 train_acc: 0.921875 test_loss: 0.192060 test_acc: 0.953125\n",
      "STEP 10000: train_loss: 0.019210 train_acc: 1.000000 test_loss: 0.090455 test_acc: 0.968750\n",
      "STEP 11000: train_loss: 0.041655 train_acc: 1.000000 test_loss: 0.085112 test_acc: 0.984375\n",
      "STEP 12000: train_loss: 0.078909 train_acc: 0.953125 test_loss: 0.161482 test_acc: 0.968750\n",
      "STEP 13000: train_loss: 0.083114 train_acc: 0.968750 test_loss: 0.042236 test_acc: 0.984375\n",
      "STEP 14000: train_loss: 0.042629 train_acc: 0.984375 test_loss: 0.060862 test_acc: 0.968750\n",
      "STEP 15000: train_loss: 0.027052 train_acc: 1.000000 test_loss: 0.155241 test_acc: 0.953125\n",
      "STEP 16000: train_loss: 0.075285 train_acc: 0.984375 test_loss: 0.061707 test_acc: 0.968750\n",
      "STEP 17000: train_loss: 0.027312 train_acc: 1.000000 test_loss: 0.037387 test_acc: 0.984375\n",
      "STEP 18000: train_loss: 0.015312 train_acc: 1.000000 test_loss: 0.161753 test_acc: 0.921875\n",
      "STEP 19000: train_loss: 0.021597 train_acc: 1.000000 test_loss: 0.212439 test_acc: 0.937500\n",
      "STEP 20000: train_loss: 0.042700 train_acc: 1.000000 test_loss: 0.040212 test_acc: 0.984375\n",
      "Train Done!\n",
      "------------------------------\n",
      "Train loss: 0.055245\n",
      "Train accuracy: 0.984709\n",
      "Test loss: 0.098183\n",
      "Test accuracy: 0.970400\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(20000):\n",
    "    images, labels = train_set.next_batch(batch_size)\n",
    "    sess.run(train_op, feed_dict={input_ph: images, label_ph: labels})\n",
    "    if e % 1000 == 999:\n",
    "        test_imgs, test_labels = test_set.next_batch(batch_size)\n",
    "        # 获取`train`数据的`summaries`以及`loss`, `acc`信息\n",
    "        sum_train, loss_train, acc_train = sess.run([merged, loss, acc], feed_dict={input_ph: images, label_ph: labels})\n",
    "        # 将`train`的`summaries`写入到`train_writer`中\n",
    "        train_writer.add_summary(sum_train, e)\n",
    "        # 获取`test`数据的`summaries`以及`loss`, `acc`信息\n",
    "        sum_test, loss_test, acc_test = sess.run([merged, loss, acc], feed_dict={input_ph: test_imgs, label_ph: test_labels})\n",
    "        # 将`test`的`summaries`写入到`test_writer`中\n",
    "        test_writer.add_summary(sum_test, e)\n",
    "        print('STEP {}: train_loss: {:.6f} train_acc: {:.6f} test_loss: {:.6f} test_acc: {:.6f}'.format(e + 1, loss_train, acc_train, loss_test, acc_test))\n",
    "\n",
    "# 关闭读写器\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "\n",
    "print('Train Done!')\n",
    "print('-'*30)\n",
    "\n",
    "# 计算所有训练样本的损失值以及正确率\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "for _ in range(train_set.num_examples // 100):\n",
    "    image, label = train_set.next_batch(100)\n",
    "    loss_train, acc_train = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    train_loss.append(loss_train)\n",
    "    train_acc.append(acc_train)\n",
    "\n",
    "print('Train loss: {:.6f}'.format(np.array(train_loss).mean()))\n",
    "print('Train accuracy: {:.6f}'.format(np.array(train_acc).mean()))\n",
    "\n",
    "# 计算所有测试样本的损失值以及正确率\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for _ in range(test_set.num_examples // 100):\n",
    "    image, label = test_set.next_batch(100)\n",
    "    loss_test, acc_test = sess.run([loss, acc], feed_dict={input_ph: image, label_ph: label})\n",
    "    test_loss.append(loss_test)\n",
    "    test_acc.append(acc_test)\n",
    "\n",
    "print('Test loss: {:.6f}'.format(np.array(test_loss).mean()))\n",
    "print('Test accuracy: {:.6f}'.format(np.array(test_acc).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打开`Tensorboard`\n",
    "\n",
    "在`test_summary`目录中输入以下命令\n",
    "```\n",
    "$ tensorboard --logdir=train:train/,test:test/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
