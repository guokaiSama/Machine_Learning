{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow 高层`API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从我们构建`AlexNet`模型可以看出,`tensorflow`在定义很多神经网络的基本单元的时候是比较复杂和冗长的.因此大部分时候人们都倾向于使用对`tensorflow`底层代码进行封装的高层`api`，比如`keras`,`slim`,`tflearn`,`skflow`等等.在这里,我们来分别使用`keras`和`slim`这两个非常流行的高层`api`尝试构造`AlexNet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/0d08dc4f9466d347e8d28a951ea51e3430c6f92c/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6b657261732e696f2f696d672f6b657261732d6c6f676f2d323031382d6c617267652d313230302e706e67)\n",
    ">Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：\n",
    "\n",
    ">- 简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）\n",
    ">- 支持CNN和RNN，或二者的结合\n",
    ">- 无缝CPU和GPU切换\n",
    "\n",
    ">Keras的设计原则是\n",
    "\n",
    ">- 用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。\n",
    ">- 模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。\n",
    ">- 易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。\n",
    "与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from utils import cifar10_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`自带了`cifar10`数据集,并且自动分成了训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.keras.datasets.cifar import load_batch\n",
    "from tensorflow.python.keras import backend as K\n",
    "# 下载地址'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "def load_data():\n",
    "  \"\"\"Loads CIFAR10 dataset.\n",
    "\n",
    "  Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "  \"\"\"\n",
    "  dirname = 'cifar-10-batches-py'\n",
    "  #origin = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
    "  path = dirname\n",
    "\n",
    "  num_train_samples = 50000\n",
    "\n",
    "  x_train = np.empty((num_train_samples, 3, 32, 32), dtype='uint8')\n",
    "  y_train = np.empty((num_train_samples,), dtype='uint8')\n",
    "\n",
    "  for i in range(1, 6):\n",
    "    fpath = os.path.join(path, 'data_batch_' + str(i))\n",
    "    (x_train[(i - 1) * 10000:i * 10000, :, :, :],\n",
    "     y_train[(i - 1) * 10000:i * 10000]) = load_batch(fpath)\n",
    "\n",
    "  fpath = os.path.join(path, 'test_batch')\n",
    "  x_test, y_test = load_batch(fpath)\n",
    "\n",
    "  y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "  y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "\n",
    "  if K.image_data_format() == 'channels_last':\n",
    "    x_train = x_train.transpose(0, 2, 3, 1)\n",
    "    x_test = x_test.transpose(0, 2, 3, 1)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float')\n",
    "x_test = x_test.astype('float')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'numpy.ndarray'>, <class 'numpy.ndarray'>)\n",
      "((50000, 32, 32, 3), (50000, 1))\n",
      "((10000, 32, 32, 3), (10000, 1))\n"
     ]
    }
   ],
   "source": [
    "print((type(x_train), type(y_train)))\n",
    "print((x_train.shape, y_train.shape))\n",
    "print((x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Keras`的数据不需要转化成`tensorflow`下的`tensor`,可以直接作为网络的输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建`Keras`模型\n",
    "#### `Keras`网络层\n",
    "`Keras`为了方便用户搭建神经网络模型, 把很多常用的层, 比如`Conv2d`, `MaxPooling2d`,封装起来, 使得输入更加简单明了.\n",
    "#### `Keras`模型\n",
    "`Keras`提供`Sequential`和`Model`两种模型的构建方法, 使用他们搭建模型就像搭积木一样非常直观简单.\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 首先定义一个`Sequential`模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从`keras`中导入我们需要的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 然后添加第一个卷积层, 卷积核为`5x5x64`, 步长为`1x1`, 激活函数是`relu`\n",
    "- 注意, 添加第一个层的时候需要注明输入的形状是什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (5, 5), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 继续添加第二个池化层, 核为`3x3`, 步长为`2x2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D([3, 3], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第三个卷积层`5x5x64`,步长为`1x1`,激活是`relu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (5, 5), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第四层是核大小`3x3`, 步长为`2x2`的池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D([3, 3], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将矩阵摊平成向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全连接层, 输出为384维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(384, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(192, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经完成了模型的搭建,.\n",
    "\n",
    "`keras`还提供了很多方法帮助我们理解模型\n",
    "- `model.summary()`\n",
    "- `plot_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               393600    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 192)               73920     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1930      \n",
      "=================================================================\n",
      "Total params: 576,778\n",
      "Trainable params: 576,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='keras_alexnet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 215.00 702.00\" width=\"215pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-698 211,-698 211,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140251443559784 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140251443559784</title>\n",
       "<polygon fill=\"none\" points=\"42,-584.5 42,-620.5 165,-620.5 165,-584.5 42,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-598.8\">conv2d_1: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140251443559504 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140251443559504</title>\n",
       "<polygon fill=\"none\" points=\"29.5,-511.5 29.5,-547.5 177.5,-547.5 177.5,-511.5 29.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-525.8\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 140251443559784&#45;&gt;140251443559504 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140251443559784-&gt;140251443559504</title>\n",
       "<path d=\"M103.5,-584.313C103.5,-576.289 103.5,-566.547 103.5,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-557.529 103.5,-547.529 100,-557.529 107,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443558328 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140251443558328</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 207,-474.5 207,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-452.8\">max_pooling2d_1: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140251443559504&#45;&gt;140251443558328 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140251443559504-&gt;140251443558328</title>\n",
       "<path d=\"M103.5,-511.313C103.5,-503.289 103.5,-493.547 103.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-484.529 103.5,-474.529 100,-484.529 107,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443558160 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140251443558160</title>\n",
       "<polygon fill=\"none\" points=\"42,-365.5 42,-401.5 165,-401.5 165,-365.5 42,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-379.8\">conv2d_2: Conv2D</text>\n",
       "</g>\n",
       "<!-- 140251443558328&#45;&gt;140251443558160 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140251443558328-&gt;140251443558160</title>\n",
       "<path d=\"M103.5,-438.313C103.5,-430.289 103.5,-420.547 103.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-411.529 103.5,-401.529 100,-411.529 107,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443557824 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140251443557824</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 207,-328.5 207,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-306.8\">max_pooling2d_2: MaxPooling2D</text>\n",
       "</g>\n",
       "<!-- 140251443558160&#45;&gt;140251443557824 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140251443558160-&gt;140251443557824</title>\n",
       "<path d=\"M103.5,-365.313C103.5,-357.289 103.5,-347.547 103.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-338.529 103.5,-328.529 100,-338.529 107,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443556928 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140251443556928</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-219.5 48.5,-255.5 158.5,-255.5 158.5,-219.5 48.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-233.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 140251443557824&#45;&gt;140251443556928 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140251443557824-&gt;140251443556928</title>\n",
       "<path d=\"M103.5,-292.313C103.5,-284.289 103.5,-274.547 103.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-265.529 103.5,-255.529 100,-265.529 107,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443392408 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140251443392408</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-146.5 52.5,-182.5 154.5,-182.5 154.5,-146.5 52.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-160.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140251443556928&#45;&gt;140251443392408 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140251443556928-&gt;140251443392408</title>\n",
       "<path d=\"M103.5,-219.313C103.5,-211.289 103.5,-201.547 103.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-192.529 103.5,-182.529 100,-192.529 107,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443491224 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140251443491224</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-73.5 52.5,-109.5 154.5,-109.5 154.5,-73.5 52.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-87.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140251443392408&#45;&gt;140251443491224 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140251443392408-&gt;140251443491224</title>\n",
       "<path d=\"M103.5,-146.313C103.5,-138.289 103.5,-128.547 103.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-119.529 103.5,-109.529 100,-119.529 107,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443054800 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140251443054800</title>\n",
       "<polygon fill=\"none\" points=\"52.5,-0.5 52.5,-36.5 154.5,-36.5 154.5,-0.5 52.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-14.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 140251443491224&#45;&gt;140251443054800 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140251443491224-&gt;140251443054800</title>\n",
       "<path d=\"M103.5,-73.3129C103.5,-65.2895 103.5,-55.5475 103.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-46.5288 103.5,-36.5288 100,-46.5289 107,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140251443558440 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140251443558440</title>\n",
       "<polygon fill=\"none\" points=\"44.5,-657.5 44.5,-693.5 162.5,-693.5 162.5,-657.5 44.5,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-671.8\">140251443558440</text>\n",
       "</g>\n",
       "<!-- 140251443558440&#45;&gt;140251443559784 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140251443558440-&gt;140251443559784</title>\n",
       "<path d=\"M103.5,-657.313C103.5,-649.289 103.5,-639.547 103.5,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107,-630.529 103.5,-620.529 100,-630.529 107,-630.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型编译\n",
    "模型构建完成之后, 我们需要用`compile`来配置训练过程\n",
    "\n",
    "`model.compile()`接受三个参数:\n",
    "- optimizer: 优化方法, 有`\"sgd\"`,`\"rmsprop\"`,`\"adgrad\"`等这样的字符串, 也可以是`keras.Optimizers`对象\n",
    "- loss: 损失函数, 有`categorical_crossentropy`, `mes`等这样的字符串, 也可以是函数形式\n",
    "- metrics: 评价函数, 如`['accuracy']` , 也支持自定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将标签转化成`onehot`形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_train = keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "`keras`训练模型非常简单, 用一个`fit`函数就可以搞定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=onehot_train, epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价\n",
    "`keras`的评价也非常简单, 用一个`evaluate`就可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_train, onehot_train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, onehot_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到, `keras`无论是在构建模型, 构建训练, 还是在评价模型上都比原生的`tensorflow`都要简洁易用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`TF-Slim`是一个可以在`tensorflow`中实现构建模型,训练模型,评估模型的轻量级代码库. 可以和原生的`tensorflow`或者其他例如`tf.contrib.learn`这样的框架自由组合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看看如何用`slim`来简化模型的定义,训练和评估. 首先从本地中导入`cifar10`数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from utils import cifar10_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们定义一个批次有64个样本\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_labels, val_imgs, val_labels = cifar10_input.load_data(data_dir='经典卷积神经网络/cifar10_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slim 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `slim`中的高级层\n",
    "`slim`也对`tensorflow`的底层`API`进行了层的封装, 像`Keras`一样, 它也具有\n",
    "- slim.conv2d\n",
    "- slim.max_pool2d\n",
    "- slim.flatten\n",
    "- slim.fully_connected\n",
    "- slim.batch_norm\n",
    "\n",
    "等等高级层, 这些接口也是用户友好的, 例如`slim.conv2d`\n",
    "\n",
    "第一个参数是输入, 第二个是输出大小, 也就是卷积核的个数, 第三个是卷积核大小, 是一个长度为2的向量, 后面还有很多默认参数,帮助我们快速定义一个卷积层,  可以说是非常简单了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### arg_scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后给大家介绍一个`slim`中独有也非常好用的一个功能: `slim.arg_scope()`\n",
    "\n",
    "我们知道, 在构建模型的时候会遇到很多相同的参数, 比如说很多卷积层或者池化层的补零策略都是`\"VALID\"`或者`\"SAME\"`, 很多变量的初始化函数都是`tf.truncated_normal_initializer`或者`tf.constant_initializer`, 如果全部手动写就会显得非常麻烦. \n",
    "\n",
    "这个时候, 可以通过`python`的`with`语句和`slim.arg_scope()`构成一个参数域, 在这个域下一次性定义好所有函数的一些默认参数, 就会非常方便了\n",
    "- - -\n",
    "使用`arg_scope`分为两个步骤\n",
    "- 定义你要对哪些函数使用默认参数\n",
    "- 定义你要使用的默认参数的具体值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义`AlexNet`的默认参数域\n",
    "def alexnet_arg_scope():\n",
    "    # 首先我们定义卷积和全连接层的参数域, 他们都用`tf.nn.relu`作为激活函数\n",
    "    # 都用`tf.truncated_normal`作为权重的初始化函数\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected], \n",
    "                       activation_fn=tf.nn.relu, \n",
    "                       weights_initializer=tf.truncated_normal_initializer(stddev=1e-2)):\n",
    "        # 在参数域内部继续定义参数域, 这里, 我们注意到在`AlexNet`中\n",
    "        # 卷积和池化的补零策略都是`VALID`.\n",
    "        with slim.arg_scope([slim.conv2d, slim.max_pool2d], \n",
    "                            padding='VALID') as sc:\n",
    "            return sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们再用`tf-slim`的高级层定义`AlexNet`模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义alexnet模型\n",
    "def alexnet(inputs, reuse=None):\n",
    "    with tf.variable_scope('AlexNet', reuse=reuse):\n",
    "        net = slim.conv2d(inputs, 64, [5, 5], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [3, 3], scope='pool1')\n",
    "        net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [3, 3], scope='pool2')\n",
    "        net = slim.flatten(net)\n",
    "        net = slim.fully_connected(net, 384, scope='fc3')\n",
    "        net = slim.fully_connected(net, 192, scope='fc4')\n",
    "        net = slim.fully_connected(net, 10, activation_fn=None, scope='classification')\n",
    "        \n",
    "        return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们使用参数域来定义`AlexNet`模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with slim.arg_scope(alexnet_arg_scope()):\n",
    "    train_out = alexnet(train_imgs)\n",
    "    val_out = alexnet(val_imgs, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slim 统计模型\n",
    "`Slim`也有类似`Keras`的模型统计功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vars_size, vars_bytes = slim.model_analyzer.analyze_vars(variables=tf.model_variables(), print_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "`slim`提供了简化训练的一些方法, 但是封装太多不够灵活, 如果想探究的话可以参考`tf-slim`的[官方说明](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim).\n",
    "\n",
    "在这里我们还是回到之前用`tensorflow`定义好的训练函数进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    train_loss = tf.losses.sparse_softmax_cross_entropy(labels=train_labels, logits=train_out, scope='train')\n",
    "    val_loss = tf.losses.sparse_softmax_cross_entropy(labels=val_labels, logits=val_out, scope='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('train'):\n",
    "        train_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(train_out, axis=-1, output_type=tf.int32), train_labels), tf.float32))\n",
    "    with tf.name_scope('train'):\n",
    "        val_acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(val_out, axis=-1, output_type=tf.int32), val_labels), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(lr, momentum=0.9)\n",
    "train_op = opt.minimize(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.learning import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_op, train_loss, train_acc, val_loss, val_acc, 20000, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出,`tf-slim`能够和原生的`tensorflow`非常好的衔接在一起, 再加上它构建模型时的优点, 让它成为了现在非常热门的代码库"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
